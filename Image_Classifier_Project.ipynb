{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image Classifier Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "I4k8mHvVG8Wi",
        "colab_type": "code",
        "outputId": "7d467940-49bb-407a-8c08-1555cfa4e89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lFUzqBbf_eJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-dcpb_pp_97y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EMyWGUixCVXU",
        "colab_type": "code",
        "outputId": "73606b6f-16f1-4bb9-beb4-a337d02f40fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace flower_data/valid/61/image_06296.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tjLPMVUiG8Wz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1KduIZmTG8W8",
        "colab_type": "code",
        "outputId": "9d45b8e7-1f85-467d-eaca-56558805e00f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_dir = '/content/flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# TODO: Define your transforms for the training and validation sets\n",
        "# TODO: Define your transforms for the training and validation sets\n",
        "train_data_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "validation_data_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), \n",
        "                         (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = ImageFolder(train_dir, transform=train_data_transforms)\n",
        "test_dataset =  ImageFolder(valid_dir, transform=validation_data_transforms)\n",
        "\n",
        "print('Loaded train images: ', len(train_dataset))\n",
        "print('Loaded test images: ', len(test_dataset))\n",
        "\n",
        "# Initialize loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded train images:  6552\n",
            "Loaded test images:  818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DMvqlfX-G8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLsJRFq3G8XS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Build and train your network\n",
        "from torch.optim import lr_scheduler\n",
        "# TODO: Build and train your network\n",
        "\n",
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#using pre-trained resnet50 from imageNet database\n",
        "model = models.resnet152(pretrained=True)\n",
        "\n",
        "#handling parameters\n",
        "for name,child in model.named_children():\n",
        "  if name in ['layer3','layer4']:\n",
        "    print(name + 'is unfrozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "    print(name + 'is frozen')\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "#creating our own classifier with name fc (as defined in resnet50)\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 512),nn.ReLU(),nn.Linear(512,102),nn.LogSoftmax(dim=1))    \n",
        "\n",
        "#using crossentropyloss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#taking steps of gradient descent with lr =0.01 and only fc parameters ,Only train the classifier parameters, feature parameters are frozen\n",
        "\n",
        "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "suwp0-9Hpej6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "epochs = 5\n",
        "\n",
        "#to have a history of losses to plot the graph\n",
        "train_losses , test_losses = [] , []\n",
        "\n",
        "# initialize tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf #set initial \"min\" to infinity\n",
        "#to put the model in training mode\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0\n",
        "  scheduler.step()\n",
        "  for images , labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "    #forward pass (feed forward)forward pass: compute predicted outputs by passing inputs to the model\n",
        "    outputs = model(images)\n",
        "    # calculate the loss\n",
        "    loss = criterion(outputs,labels)\n",
        "    #gradient descent ,backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "    # perform a single optimization step (parameter update)\n",
        "    optimizer.step()\n",
        "    # update running training loss\n",
        "    running_loss += loss.item()\n",
        "  # initialize lists to monitor test loss and accuracy\n",
        "  test_loss = 0\n",
        "  accuracy = 0\n",
        "  #we no longer gradients to be calculated\n",
        "  with torch.no_grad():\n",
        "    model.eval() # prep model for evaluation\n",
        "    for images , labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      logps = model(images) # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      test_loss += criterion(logps,labels) #calculate the loss and update the loss\n",
        "      ps = torch.exp(logps)\n",
        "      top_p , top_class = ps.topk(1,dim=1)\n",
        "      equals = top_class == labels.view(*top_class.shape)\n",
        "      accuracy += torch.mean(equals.type(torch.FloatTensor))    \n",
        "   \n",
        "  train_losses.append(running_loss/len(train_loader))\n",
        "  test_losses.append(test_loss/len(test_loader))\n",
        "  print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "        \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
        "  model.train() \n",
        "  # save model if validation loss has decreased\n",
        "  if test_loss/len(test_loader) <= valid_loss_min:\n",
        "        print('test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,test_loss/len(test_loader))) \n",
        "        torch.save(model.state_dict(), 'model_2.pt')\n",
        "        valid_loss_min = test_loss/len(test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQ5GWnhXG8XY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Save the checkpoint \n",
        "torch.save(model.state_dict(), 'model_2.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLEaeuWQgupQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we need pillow version of 5.3.0\n",
        "# we will uninstall the older version first\n",
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "# this should print 5.3.0. If it doesn't, then restart your runtime:\n",
        "# Menu > Runtime > Restart Runtime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtKkalpdVstq",
        "colab_type": "code",
        "outputId": "a65e6e47-a057-42ca-9ef2-040530fefd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#for mounting Google Drive to Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xMNbUZObcaB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Save the checkpoint \n",
        "torch.save(model.state_dict(), 'drive/My Drive/checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpvT8emqG8Xe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
        "def load_model(checkpoint_path):\n",
        "    chpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model = models.resnet152(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "   \n",
        "    model.fc = nn.Sequential(nn.Linear(2048, 512),nn.ReLU(),nn.Linear(512,102),nn.LogSoftmax(dim=1))\n",
        "    \n",
        "    model.load_state_dict(chpt, strict=False)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
